{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44409ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Train shape: (2520, 64, 64, 3)\n",
      "Raw Test shape: (372, 64, 64, 3)\n",
      "HOG Train shape: (2016, 1764)\n",
      "PCA Train shape: (2016, 100)\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Params: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best CV Score: 1.0\n",
      "\n",
      "Validation Accuracy: 1.0\n",
      "\n",
      "Test Accuracy: 0.7043010752688172\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       paper       0.62      0.66      0.64       124\n",
      "        rock       0.84      0.86      0.85       124\n",
      "    scissors       0.65      0.59      0.62       124\n",
      "\n",
      "    accuracy                           0.70       372\n",
      "   macro avg       0.70      0.70      0.70       372\n",
      "weighted avg       0.70      0.70      0.70       372\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 82   4  38]\n",
      " [ 16 107   1]\n",
      " [ 35  16  73]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.feature import hog\n",
    "from skimage import color\n",
    "\n",
    "# ==========================\n",
    "# 1) H√ÄM ƒê·ªåC ·∫¢NH & G√ÅN NH√ÉN\n",
    "# ==========================\n",
    "def load_data_from_folder(base_path, img_size=(64,64)):\n",
    "    X, y = [], []\n",
    "    classes = os.listdir(base_path)\n",
    "    for label in classes:\n",
    "        class_path = os.path.join(base_path, label)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        for file in os.listdir(class_path):\n",
    "            file_path = os.path.join(class_path, file)\n",
    "            img = cv2.imread(file_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.resize(img, img_size)\n",
    "            X.append(img)\n",
    "            y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# ==========================\n",
    "# 2) TR√çCH HOG FEATURE\n",
    "# ==========================\n",
    "def extract_hog_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        gray = color.rgb2gray(img)  # chuy·ªÉn grayscale\n",
    "        hog_feat = hog(gray, \n",
    "                       pixels_per_cell=(8,8), \n",
    "                       cells_per_block=(2,2), \n",
    "                       feature_vector=True)\n",
    "        features.append(hog_feat)\n",
    "    return np.array(features)\n",
    "\n",
    "# ==========================\n",
    "# 3) LOAD D·ªÆ LI·ªÜU\n",
    "# ==========================\n",
    "train_dir = r\"D:\\BT_KNN\\Rock-Paper-Scissors\\train\"\n",
    "test_dir  = r\"D:\\BT_KNN\\Rock-Paper-Scissors\\test\"\n",
    "\n",
    "X_train, y_train = load_data_from_folder(train_dir)\n",
    "X_test,  y_test  = load_data_from_folder(test_dir)\n",
    "\n",
    "print(\"Raw Train shape:\", X_train.shape)\n",
    "print(\"Raw Test shape:\", X_test.shape)\n",
    "\n",
    "# encode nh√£n\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test  = le.transform(y_test)\n",
    "\n",
    "# t√°ch train th√†nh train + val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "# ==========================\n",
    "# 4) TR√çCH HOG\n",
    "# ==========================\n",
    "X_train_hog = extract_hog_features(X_train)\n",
    "X_val_hog   = extract_hog_features(X_val)\n",
    "X_test_hog  = extract_hog_features(X_test)\n",
    "\n",
    "print(\"HOG Train shape:\", X_train_hog.shape)\n",
    "\n",
    "# ==========================\n",
    "# 5) CHU·∫®N H√ìA + PCA\n",
    "# ==========================\n",
    "scaler = StandardScaler()\n",
    "X_train_hog = scaler.fit_transform(X_train_hog)\n",
    "X_val_hog   = scaler.transform(X_val_hog)\n",
    "X_test_hog  = scaler.transform(X_test_hog)\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "X_train_pca = pca.fit_transform(X_train_hog)\n",
    "X_val_pca   = pca.transform(X_val_hog)\n",
    "X_test_pca  = pca.transform(X_test_hog)\n",
    "\n",
    "print(\"PCA Train shape:\", X_train_pca.shape)\n",
    "\n",
    "# ==========================\n",
    "# 6) GRID SEARCH KNN\n",
    "# ==========================\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "grid = GridSearchCV(knn, param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid.fit(X_train_pca, y_train)\n",
    "\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"Best CV Score:\", grid.best_score_)\n",
    "\n",
    "# ==========================\n",
    "# 7) ƒê√ÅNH GI√Å\n",
    "# ==========================\n",
    "best_knn = grid.best_estimator_\n",
    "\n",
    "y_val_pred = best_knn.predict(X_val_pca)\n",
    "print(\"\\nValidation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = best_knn.predict(X_test_pca)\n",
    "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred, target_names=le.classes_))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aba5197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(img_path, img_size=(64,64)):\n",
    "    # ƒë·ªçc ·∫£nh\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(\"‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh:\", img_path)\n",
    "        return\n",
    "    img = cv2.resize(img, img_size)\n",
    "\n",
    "    # tr√≠ch HOG\n",
    "    gray = color.rgb2gray(img)\n",
    "    hog_feat = hog(gray, pixels_per_cell=(8,8), cells_per_block=(2,2), feature_vector=True)\n",
    "\n",
    "    # chu·∫©n h√≥a + PCA\n",
    "    hog_feat = scaler.transform([hog_feat])\n",
    "    hog_feat = pca.transform(hog_feat)\n",
    "\n",
    "    # d·ª± ƒëo√°n\n",
    "    pred = best_knn.predict(hog_feat)[0]\n",
    "    label = le.inverse_transform([pred])[0]\n",
    "\n",
    "    # hi·ªÉn th·ªã\n",
    "    cv2.imshow(f\"Prediction: {label}\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c822a784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "·∫¢nh d·ª± ƒëo√°n l√†: rock\n"
     ]
    }
   ],
   "source": [
    "# v√≠ d·ª• test m·ªôt ·∫£nh b·∫•t k·ª≥\n",
    "img_path = r\"D:\\BT_KNN\\Rock-Paper-Scissors\\test\\rock\\testrock04-27.png\"\n",
    "label = predict_single_image(img_path)\n",
    "print(\"·∫¢nh d·ª± ƒëo√°n l√†:\", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24956a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "·∫¢nh d·ª± ƒëo√°n l√†: rock\n"
     ]
    }
   ],
   "source": [
    "# v√≠ d·ª• test m·ªôt ·∫£nh b·∫•t k·ª≥\n",
    "img_path = r\"Bua.jpg\"\n",
    "label = predict_single_image(img_path)\n",
    "print(\"·∫¢nh d·ª± ƒëo√°n l√†:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7979ae0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data shape: (2188, 64, 64, 3)\n",
      "Train: (1531, 64, 64, 3) Val: (328, 64, 64, 3) Test: (329, 64, 64, 3)\n",
      "HOG Train shape: (1531, 1764)\n",
      "PCA Train shape: (1531, 100)\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Params: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best CV Score: 0.9803998311653429\n",
      "\n",
      "Validation Accuracy: 0.9908536585365854\n",
      "\n",
      "Test Accuracy: 0.9787234042553191\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       paper       0.95      0.98      0.97       107\n",
      "        rock       0.99      1.00      1.00       109\n",
      "    scissors       0.99      0.96      0.97       113\n",
      "\n",
      "    accuracy                           0.98       329\n",
      "   macro avg       0.98      0.98      0.98       329\n",
      "weighted avg       0.98      0.98      0.98       329\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[105   1   1]\n",
      " [  0 109   0]\n",
      " [  5   0 108]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.feature import hog\n",
    "from skimage import color\n",
    "\n",
    "# ==========================\n",
    "# 1) H√ÄM ƒê·ªåC ·∫¢NH & G√ÅN NH√ÉN\n",
    "# ==========================\n",
    "def load_data_from_folder(base_path, img_size=(64,64)):\n",
    "    X, y = [], []\n",
    "    classes = os.listdir(base_path)\n",
    "    for label in classes:\n",
    "        class_path = os.path.join(base_path, label)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        for file in os.listdir(class_path):\n",
    "            file_path = os.path.join(class_path, file)\n",
    "            img = cv2.imread(file_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.resize(img, img_size)\n",
    "            X.append(img)\n",
    "            y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# ==========================\n",
    "# 2) TR√çCH HOG FEATURE\n",
    "# ==========================\n",
    "def extract_hog_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        gray = color.rgb2gray(img)  # chuy·ªÉn grayscale\n",
    "        hog_feat = hog(gray,\n",
    "                       pixels_per_cell=(8,8),\n",
    "                       cells_per_block=(2,2),\n",
    "                       feature_vector=True)\n",
    "        features.append(hog_feat)\n",
    "    return np.array(features)\n",
    "\n",
    "# ==========================\n",
    "# 3) LOAD D·ªÆ LI·ªÜU ARCHIVE\n",
    "# ==========================\n",
    "archive_dir = r\"archive\"  # ch·ª©a paper/rock/scissors\n",
    "\n",
    "X, y = load_data_from_folder(archive_dir)\n",
    "print(\"Raw data shape:\", X.shape)\n",
    "\n",
    "# encode nh√£n\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# chia train (70%), val (15%), test (15%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
    "\n",
    "# ==========================\n",
    "# 4) TR√çCH HOG\n",
    "# ==========================\n",
    "X_train_hog = extract_hog_features(X_train)\n",
    "X_val_hog   = extract_hog_features(X_val)\n",
    "X_test_hog  = extract_hog_features(X_test)\n",
    "\n",
    "print(\"HOG Train shape:\", X_train_hog.shape)\n",
    "\n",
    "# ==========================\n",
    "# 5) CHU·∫®N H√ìA + PCA\n",
    "# ==========================\n",
    "scaler = StandardScaler()\n",
    "X_train_hog = scaler.fit_transform(X_train_hog)\n",
    "X_val_hog   = scaler.transform(X_val_hog)\n",
    "X_test_hog  = scaler.transform(X_test_hog)\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "X_train_pca = pca.fit_transform(X_train_hog)\n",
    "X_val_pca   = pca.transform(X_val_hog)\n",
    "X_test_pca  = pca.transform(X_test_hog)\n",
    "\n",
    "print(\"PCA Train shape:\", X_train_pca.shape)\n",
    "\n",
    "# ==========================\n",
    "# 6) GRID SEARCH KNN (d√πng train + val)\n",
    "# ==========================\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "grid = GridSearchCV(knn, param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid.fit(X_train_pca, y_train)\n",
    "\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"Best CV Score:\", grid.best_score_)\n",
    "\n",
    "# ==========================\n",
    "# 7) ƒê√ÅNH GI√Å\n",
    "# ==========================\n",
    "best_knn = grid.best_estimator_\n",
    "\n",
    "# Validation\n",
    "y_val_pred = best_knn.predict(X_val_pca)\n",
    "print(\"\\nValidation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "\n",
    "# Test\n",
    "y_test_pred = best_knn.predict(X_test_pca)\n",
    "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred, target_names=le.classes_))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b249647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(img_path, img_size=(64,64)):\n",
    "    # ƒë·ªçc ·∫£nh\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(\"‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh:\", img_path)\n",
    "        return None\n",
    "    img = cv2.resize(img, img_size)\n",
    "\n",
    "    # tr√≠ch HOG\n",
    "    gray = color.rgb2gray(img)\n",
    "    hog_feat = hog(gray, pixels_per_cell=(8,8), cells_per_block=(2,2), feature_vector=True)\n",
    "\n",
    "    # chu·∫©n h√≥a + PCA (d√πng scaler & pca ƒë√£ fit t·ª´ train)\n",
    "    hog_feat = scaler.transform([hog_feat])\n",
    "    hog_feat = pca.transform(hog_feat)\n",
    "\n",
    "    # d·ª± ƒëo√°n\n",
    "    pred = best_knn.predict(hog_feat)[0]\n",
    "    label = le.inverse_transform([pred])[0]\n",
    "\n",
    "    # hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "    print(f\"·∫¢nh {os.path.basename(img_path)} d·ª± ƒëo√°n l√† üëâ {label}\")\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77373c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "·∫¢nh Q2.jpg d·ª± ƒëo√°n l√† üëâ rock\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.str_('rock')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test ·∫£nh ngo√†i dataset\n",
    "img_path = r\"Q2.jpg\"   # ƒë·ªïi th√†nh ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø c·ªßa b·∫°n\n",
    "predict_single_image(img_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Uni_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
